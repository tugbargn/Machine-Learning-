{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tubi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QFGmnwxAn_oBGC-O1h8P5LHlp03qU-MZ",
      "authorship_tag": "ABX9TyP36/+CaYM+g10q3bvQPZG9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tugbargn/Machine-Learning-/blob/main/cloud%20detection%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAJCF8STnWyx",
        "outputId": "1e7f57ad-a4fd-43ca-f6d5-73a9e28b934f"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from os.path import join\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Softmax\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/SWIMSEG/metadata.csv\")\n",
        "#data.head()\n",
        "number = data[\"Number\"]\n",
        "#print(number)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.3)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/SWIMSEG/train/',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/SWIMSEG/train/',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n",
        "#print(train_generator)\n",
        "#print(validation_generator)\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(2,activation = \"softmax\" ))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=32,\n",
        "        epochs=10,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=800)\n",
        "        #steps_per_epoch = len(X_train)\n",
        "## Sonra drop out ve batch normalization ekleyerek modeli optimize edebilirsiniz"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2256 images belonging to 2 classes.\n",
            "Found 2256 images belonging to 2 classes.\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_65 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 34, 34, 64)        36928     \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 73984)             0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 2)                 147970    \n",
            "=================================================================\n",
            "Total params: 204,290\n",
            "Trainable params: 204,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.8219 - accuracy: 0.6857WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 800 batches). You may need to use the repeat() function when building your dataset.\n",
            "32/32 [==============================] - 84s 3s/step - loss: 0.8107 - accuracy: 0.6901 - val_loss: 0.0361 - val_accuracy: 0.9956\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 46s 1s/step - loss: 0.0447 - accuracy: 0.9920\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 50s 2s/step - loss: 0.0182 - accuracy: 0.9966\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 45s 1s/step - loss: 0.0197 - accuracy: 0.9973\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 46s 1s/step - loss: 0.0137 - accuracy: 0.9985\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 46s 1s/step - loss: 0.0236 - accuracy: 0.9962\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 46s 1s/step - loss: 0.0137 - accuracy: 0.9975\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 45s 1s/step - loss: 0.0154 - accuracy: 0.9980\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 47s 1s/step - loss: 0.0200 - accuracy: 0.9966\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 47s 1s/step - loss: 0.0026 - accuracy: 0.9997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4d00965dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}