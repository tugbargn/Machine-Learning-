{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Densenet",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Lty2aRzwo3g3Ga7C-R-FGox4sHvRMfkn",
      "authorship_tag": "ABX9TyPanK1DEVJL+oLTQfXHVjFE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tugbargn/Machine-Learning-/blob/main/Densenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoeupv1RVsIo"
      },
      "source": [
        "#DENSENET\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnOfoPQCV6Yg"
      },
      "source": [
        "###DENSENET 121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSw7e3NxpDcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3081d5e-4890-427b-eb97-dabc38b1490b"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing import image\n",
        "from os.path import join\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Softmax, ZeroPadding2D\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.core import Flatten, Dense, Dropout \n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D,BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.3)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/Train',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/Train',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13536 images belonging to 2 classes.\n",
            "Found 13536 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcCTJdjnUEVZ"
      },
      "source": [
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "\n",
        "model = DenseNet121(include_top= True, weights='imagenet', input_shape=(224,224,3))\n",
        "x = model.output\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "model = Model(inputs = model.input, outputs=predictions)\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7r5MwOkVoco"
      },
      "source": [
        "\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID)\n",
        "\n",
        "#plot_confusion_matrix(model, train_generator, validation_genarator)  \n",
        "#plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo35jpjZPwEV"
      },
      "source": [
        "model=build_densenet121()\n",
        "# Modelimizi görselleştirelim\n",
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(model, \n",
        "           show_shapes = True, \n",
        "           show_layer_names = True, \n",
        "           rankdir = 'TB', \n",
        "           expand_nested = False, \n",
        "           dpi = 60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JlC_6DRP1KO"
      },
      "source": [
        "plt.plot(history.history['accuracy'],color = 'red')\n",
        "plt.plot(history.history['val_accuracy'],color = 'blue')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc = 'best')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'],color = 'red')\n",
        "plt.plot(history.history['val_loss'],color = 'blue')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'],loc = 'best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgQkZsWwWGPt"
      },
      "source": [
        "###DENSENET 201\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EKNrElNWJ9F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJVonglVWLhf"
      },
      "source": [
        "###DENSENET 201\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCAQlxtSWO8s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbVYcIjnWQP5"
      },
      "source": [
        "###DENSENET 161"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYJ24TCqWTJ8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_2MZbrTWT2g"
      },
      "source": [
        "###DENSENET 169\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub606R73WWty"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}