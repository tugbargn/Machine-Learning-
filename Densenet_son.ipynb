{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Densenet_son.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1uxyrICoQJxn4kUngmZXsmc5JRRxhcLt2",
      "authorship_tag": "ABX9TyOcVu+7INtC3/4/QfwQsrO+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tugbargn/Machine-Learning-/blob/main/Densenet_son.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRUn6c_zv1RK"
      },
      "source": [
        "#DENSENET\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLwpG285v5q3"
      },
      "source": [
        "###DENSENET 121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QuLt5s5vUdn",
        "outputId": "76d83ede-9207-44e2-c0a1-1589b502a562"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Softmax, ZeroPadding2D, GlobalAveragePooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.core import Flatten, Dense, Dropout \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.optimizers import Adam, SGD, Adamax, Adagrad\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.3)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13550 images belonging to 2 classes.\n",
            "Found 13550 images belonging to 2 classes.\n",
            "Found 13550 images belonging to 2 classes.\n",
            "Found 13550 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1K7FjeQzLrJ",
        "outputId": "271c08e3-9335-4354-dfb8-41a88a60d872"
      },
      "source": [
        "def build_densenet121():\n",
        "    densenet = DenseNet121(weights='imagenet', include_top=False)\n",
        "\n",
        "    input = Input(shape=(224, 224, 3))\n",
        "    x = Convolution2D(3, (3, 3), padding='same')(input)\n",
        "    \n",
        "    x = densenet(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # multi output\n",
        "    output = Dense(2,activation = 'softmax', name='root')(x)\n",
        " \n",
        "\n",
        "    # model\n",
        "    model = Model(input,output)\n",
        "    \n",
        "    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    history = model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID)\n",
        "    \n",
        "    return model\n",
        "\n",
        "model=build_densenet121()\n",
        "y_pred = model.predict(test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 224, 224, 3)       84        \n",
            "_________________________________________________________________\n",
            "densenet121 (Functional)     (None, None, None, 1024)  7037504   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "root (Dense)                 (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 7,305,622\n",
            "Trainable params: 7,219,414\n",
            "Non-trainable params: 86,208\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            " 97/423 [=====>........................] - ETA: 1:49:41 - loss: 0.3360 - accuracy: 0.8373"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H09wKJ4wR2I"
      },
      "source": [
        "###DENSENET 201"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJtG8Qz7wYCK"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Softmax, ZeroPadding2D, GlobalAveragePooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.core import Flatten, Dense, Dropout \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.optimizers import Adam, SGD, Adamax, Adagrad\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.3)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghjjXVGo9h2j"
      },
      "source": [
        "def build_densenet201():\n",
        "    densenet = DenseNet201(weights='imagenet', include_top=False)\n",
        "\n",
        "    input = Input(shape=(224, 224, 3))\n",
        "    x = Convolution2D(3, (3, 3), padding='same')(input)\n",
        "    \n",
        "    x = densenet(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # multi output\n",
        "    output = Dense(2,activation = 'softmax', name='root')(x)\n",
        " \n",
        "\n",
        "    # model\n",
        "    model = Model(input,output)\n",
        "    \n",
        "    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    history = model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID)\n",
        "    \n",
        "    return model\n",
        "\n",
        "model=build_densenet201()\n",
        "y_pred = model.predict(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Scxt8I8wZCa"
      },
      "source": [
        "###DENSENET 161"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3K-rvSq9rCQ"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Softmax, ZeroPadding2D, GlobalAveragePooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.core import Flatten, Dense, Dropout \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.optimizers import Adam, SGD, Adamax, Adagrad\n",
        "from tensorflow.keras.applications import DenseNet161\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.3)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcnB3FVj8QpW"
      },
      "source": [
        "def build_densenet161():\n",
        "    densenet = DenseNet161(weights='imagenet', include_top=False)\n",
        "\n",
        "    input = Input(shape=(224, 224, 3))\n",
        "    x = Convolution2D(3, (3, 3), padding='same')(input)\n",
        "    \n",
        "    x = densenet(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # multi output\n",
        "    output = Dense(2,activation = 'softmax', name='root')(x)\n",
        " \n",
        "\n",
        "    # model\n",
        "    model = Model(input,output)\n",
        "    \n",
        "    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    history = model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID)\n",
        "    \n",
        "    return model\n",
        "\n",
        "model=build_densenet161()\n",
        "y_pred = model.predict(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJDpA5hxwc31"
      },
      "source": [
        "###DENSENET 169"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9Sv3FNOwedL"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Softmax, ZeroPadding2D, GlobalAveragePooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.core import Flatten, Dense, Dropout \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.optimizers import Adam, SGD, Adamax, Adagrad\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.3)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAuSqP6T9xEK"
      },
      "source": [
        "def build_densenet169():\n",
        "    densenet = DenseNet169(weights='imagenet', include_top=False)\n",
        "\n",
        "    input = Input(shape=(224, 224, 3))\n",
        "    x = Convolution2D(3, (3, 3), padding='same')(input)\n",
        "    \n",
        "    x = densenet(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # multi output\n",
        "    output = Dense(2,activation = 'softmax', name='root')(x)\n",
        " \n",
        "\n",
        "    # model\n",
        "    model = Model(input,output)\n",
        "    \n",
        "    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    history = model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID)\n",
        "    \n",
        "    return model\n",
        "\n",
        "model=build_densenet169()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}