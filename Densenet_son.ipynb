{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Densenet_son.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6Scxt8I8wZCa",
        "GJDpA5hxwc31"
      ],
      "mount_file_id": "1RG6phITDUfmH51hOd7DmH0Nocr7tVwmM",
      "authorship_tag": "ABX9TyMuUDzHWI/Kp+LKLdczbFvi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tugbargn/Machine-Learning-/blob/main/Densenet_son.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRUn6c_zv1RK"
      },
      "source": [
        "#DENSENET\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLwpG285v5q3"
      },
      "source": [
        "###DENSENET 121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QuLt5s5vUdn",
        "outputId": "473c40f0-8ed8-43da-b8e9-68553e24b745"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Softmax, ZeroPadding2D, GlobalAveragePooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.core import Flatten, Dense, Dropout \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.optimizers import Adam, SGD, Adamax, Adagrad\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.3)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "history\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13550 images belonging to 2 classes.\n",
            "Found 13550 images belonging to 2 classes.\n",
            "Found 13550 images belonging to 2 classes.\n",
            "Found 13550 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S1K7FjeQzLrJ",
        "outputId": "03a089a3-458f-49a5-e156-27ed62c1a977"
      },
      "source": [
        "def build_densenet121():\n",
        "    densenet = DenseNet121(weights='imagenet', include_top=False)\n",
        "\n",
        "    input = Input(shape=(224, 224, 3))\n",
        "    x = Convolution2D(3, (3, 3), padding='same')(input)\n",
        "    \n",
        "    x = densenet(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # multi output\n",
        "    output = Dense(2,activation = 'softmax', name='root')(x)\n",
        " \n",
        "\n",
        "    # model\n",
        "    model = Model(input,output)\n",
        "    \n",
        "    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    history = model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID)\n",
        "    plt.plot(history.history['accuracy'],color = 'red')\n",
        "    plt.plot(history.history['val_accuracy'],color = 'blue')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Validation'], loc = 'best')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(history.history['loss'],color = 'red')\n",
        "    plt.plot(history.history['val_loss'],color = 'blue')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Validation'],loc = 'best')\n",
        "    plt.show()\n",
        "    return model\n",
        "\n",
        "model=build_densenet121()\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 3)       84        \n",
            "_________________________________________________________________\n",
            "densenet121 (Functional)     (None, None, None, 1024)  7037504   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "root (Dense)                 (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 7,305,622\n",
            "Trainable params: 7,219,414\n",
            "Non-trainable params: 86,208\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "423/423 [==============================] - 246s 560ms/step - loss: 0.1164 - accuracy: 0.9544 - val_loss: 1.4971e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "423/423 [==============================] - 235s 555ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 3.0455e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "423/423 [==============================] - 235s 554ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.4798e-06 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "423/423 [==============================] - 235s 555ms/step - loss: 6.6817e-04 - accuracy: 1.0000 - val_loss: 9.7550e-07 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "423/423 [==============================] - 236s 559ms/step - loss: 6.3205e-04 - accuracy: 0.9998 - val_loss: 1.3164e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "423/423 [==============================] - 236s 557ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 8.1960e-07 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "423/423 [==============================] - 235s 555ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.3415e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "423/423 [==============================] - 235s 555ms/step - loss: 4.0178e-04 - accuracy: 1.0000 - val_loss: 3.7099e-07 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "423/423 [==============================] - 235s 555ms/step - loss: 9.7540e-04 - accuracy: 0.9997 - val_loss: 8.4514e-07 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "423/423 [==============================] - 235s 556ms/step - loss: 2.0011e-04 - accuracy: 1.0000 - val_loss: 1.1542e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TScbSQQ6Zr8O"
      },
      "source": [
        "y_pred = model.predict(test_generator)\n",
        "y_test = test_generator\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "#kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print('Cohens kappa: %f' % kappa)\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print('ROC AUC: %f' % auc)\n",
        "\n",
        "# precision\n",
        "pre=precision_score(y_test, y_pred)\n",
        "print('Precision =  %.3f'%pre)\n",
        "\n",
        "# confusion matrix\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H09wKJ4wR2I"
      },
      "source": [
        "###DENSENET 201"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJtG8Qz7wYCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433e7a06-af7c-48ed-b6a7-6114df180186"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Softmax, ZeroPadding2D, GlobalAveragePooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.core import Flatten, Dense, Dropout \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.optimizers import Adam, SGD, Adamax, Adagrad\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.3)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13550 images belonging to 2 classes.\n",
            "Found 13550 images belonging to 2 classes.\n",
            "Found 13550 images belonging to 2 classes.\n",
            "Found 13550 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghjjXVGo9h2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babe803a-505a-42c7-a3c1-5bad4a9fa9ab"
      },
      "source": [
        "def build_densenet201():\n",
        "    densenet = DenseNet201(weights='imagenet', include_top=False)\n",
        "\n",
        "    input = Input(shape=(224, 224, 3))\n",
        "    x = Convolution2D(3, (3, 3), padding='same')(input)\n",
        "    \n",
        "    x = densenet(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # multi output\n",
        "    output = Dense(2,activation = 'softmax', name='root')(x)\n",
        " \n",
        "\n",
        "    # model\n",
        "    model = Model(input,output)\n",
        "    \n",
        "    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    history = model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID)\n",
        "    plt.plot(history.history['accuracy'],color = 'red')\n",
        "    plt.plot(history.history['val_accuracy'],color = 'blue')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Validation'], loc = 'best')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(history.history['loss'],color = 'red')\n",
        "    plt.plot(history.history['val_loss'],color = 'blue')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Validation'],loc = 'best')\n",
        "    plt.show()\n",
        "    return model\n",
        "\n",
        "model=build_densenet201()\n",
        "y_pred = model.predict(test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74842112/74836368 [==============================] - 1s 0us/step\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 224, 224, 3)       84        \n",
            "_________________________________________________________________\n",
            "densenet201 (Functional)     (None, None, None, 1920)  18321984  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1920)              7680      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               491776    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "root (Dense)                 (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 18,823,062\n",
            "Trainable params: 18,589,654\n",
            "Non-trainable params: 233,408\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "423/423 [==============================] - 336s 747ms/step - loss: 0.0889 - accuracy: 0.9681 - val_loss: 0.0049 - val_accuracy: 0.9998\n",
            "Epoch 2/10\n",
            "423/423 [==============================] - 309s 730ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 1.1309e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "399/423 [===========================>..] - ETA: 13s - loss: 7.0719e-04 - accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Scxt8I8wZCa"
      },
      "source": [
        "###DENSENET 161"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3K-rvSq9rCQ"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Softmax, ZeroPadding2D, GlobalAveragePooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.core import Flatten, Dense, Dropout \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.optimizers import Adam, SGD, Adamax, Adagrad\n",
        "from tensorflow.keras.applications import DenseNet161\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.3)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcnB3FVj8QpW"
      },
      "source": [
        "def build_densenet161():\n",
        "    densenet = DenseNet161(weights='imagenet', include_top=False)\n",
        "\n",
        "    input = Input(shape=(224, 224, 3))\n",
        "    x = Convolution2D(3, (3, 3), padding='same')(input)\n",
        "    \n",
        "    x = densenet(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # multi output\n",
        "    output = Dense(2,activation = 'softmax', name='root')(x)\n",
        " \n",
        "\n",
        "    # model\n",
        "    model = Model(input,output)\n",
        "    \n",
        "    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    history = model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID)\n",
        "    plt.plot(history.history['accuracy'],color = 'red')\n",
        "    plt.plot(history.history['val_accuracy'],color = 'blue')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Validation'], loc = 'best')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(history.history['loss'],color = 'red')\n",
        "    plt.plot(history.history['val_loss'],color = 'blue')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Validation'],loc = 'best')\n",
        "    plt.show()\n",
        "    return model\n",
        "\n",
        "model=build_densenet161()\n",
        "y_pred = model.predict(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJDpA5hxwc31"
      },
      "source": [
        "###DENSENET 169"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9Sv3FNOwedL"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Softmax, ZeroPadding2D, GlobalAveragePooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.core import Flatten, Dense, Dropout \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.optimizers import Adam, SGD, Adamax, Adagrad\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.3)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/MachineLearning',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAuSqP6T9xEK"
      },
      "source": [
        "def build_densenet169():\n",
        "    densenet = DenseNet169(weights='imagenet', include_top=False)\n",
        "\n",
        "    input = Input(shape=(224, 224, 3))\n",
        "    x = Convolution2D(3, (3, 3), padding='same')(input)\n",
        "    \n",
        "    x = densenet(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # multi output\n",
        "    output = Dense(2,activation = 'softmax', name='root')(x)\n",
        " \n",
        "\n",
        "    # model\n",
        "    model = Model(input,output)\n",
        "    \n",
        "    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    history = model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID)\n",
        "    plt.plot(history.history['accuracy'],color = 'red')\n",
        "    plt.plot(history.history['val_accuracy'],color = 'blue')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Validation'], loc = 'best')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(history.history['loss'],color = 'red')\n",
        "    plt.plot(history.history['val_loss'],color = 'blue')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train','Validation'],loc = 'best')\n",
        "    plt.show()\n",
        "    return model\n",
        "\n",
        "model=build_densenet169()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}